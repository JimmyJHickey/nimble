% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Laplace.R
\name{AGHQuad_BASE}
\alias{AGHQuad_BASE}
\alias{buildOneLaplace1D}
\alias{buildOneLaplace}
\alias{buildLaplace}
\alias{laplace}
\alias{Laplace}
\title{Laplace approximation}
\usage{
AGHQuad_BASE()

buildOneLaplace1D(
  model,
  paramNodes,
  randomEffectsNodes,
  calcNodes,
  optimControl,
  optimMethod,
  optimStart
)

buildOneLaplace(
  model,
  paramNodes,
  randomEffectsNodes,
  calcNodes,
  optimControl,
  optimMethod,
  optimStart
)

buildLaplace(
  model,
  paramNodes,
  randomEffectsNodes,
  calcNodes,
  calcNodesExtra,
  control = list()
)
}
\arguments{
\item{model}{a NIMBLE model object, such as returned by \code{nimbleModel}.
The model must have automatic derivatives (AD) turned on, using
\code{buildDerivs=TRUE} in \code{nimbleModel}.}

\item{paramNodes}{a character vector of names of parameter nodes in the
model; defaults to top-level stochastic nodes, as determined by
\code{model$getNodeNames(topOnly=TRUE, stochOnly=TRUE)}. If
\code{allowNonPriors} is \code{TRUE}, top-level determinisic nodes are also
treated as parameters (i.e. \code{stochOnly=FALSE}). Alternatively,
\code{paramNodes} can be a list in the format returned by
\code{setupMargNodes}, in which case \code{randomEffectsNodes},
\code{calcNodes}, and \code{calcNodesExtra} are not needed (and will be
ignored).}

\item{randomEffectsNodes}{a character vector of names of unobserved (latent)
nodes to marginalize (integrate) over using the Laplace approximation;
defaults to latent stochastic nodes that depend on \code{paramNodes}.}

\item{calcNodes}{a character vector of names of nodes for calculating the
integrand for Laplace approximation; defaults to nodes that depend on
\code{randomEffectsNodes}, as determined by
\code{model$geteDependencies(randomEffectsNodes)} (which will include
\code{randomEffectsNodes}). There may be deterministic nodes between
\code{paramNodes} and \code{randomEffectsNodes}. These will be included in
calculations automatically and thus do not need to be included in
\code{calcNodes} (but there is no problem if they are).}

\item{optimControl}{a list of control parameters for the inner optimization
(of randomEffectsNodes) of Laplace approximation using \code{optim}. This
is used in the internal nimbleFunctions \code{buildOneAGHQuad} and
\code{buildOneAGHQuad1D}. See 'Details' of \code{\link{optim}} for further
information.}

\item{optimMethod}{optimization method to be used in \code{optim} for the
inner optimization. This is used in the internal nimbleFunctions
\code{buildOneAGHQuad} and \code{buildOneAGHQuad1D}. See 'Details' of
\code{\link{optim}}. Currently \code{nimOptim} supports:
"\code{Nelder-Mead}", "\code{BFGS}", "\code{CG}", "\code{L-BFGS-B}". By
default, method "\code{CG}" is used for \code{buildOneAGHQuad1D} and
"\code{BFGS}" for \code{buildOneAGHQuad}.}

\item{optimStart}{choice of starting values for the inner optimization. This
could be \code{"last"}, \code{"last.best"}, or a vector of user provided
values. \code{"last"} means the most recent random effects values left in
the model will be used. When finding the MLE, the most recent values will
be the result of the most recent inner optimization, from the previous
parameter values. \code{"last.best"} means the random effects values
corresponding to the largest Laplace likelihood (from any call to the
`Laplace` method, including during an MLE search) will be used (even if it
was not the most recent Laplace likelihood). By default, the initial random
effects values will be used for inner optimization.}

\item{calcNodesExtra}{a character vector of names of nodes for
calculating terms in the log-likelihood that do not depend on any
\code{randomEffectsNodes}, and thus are not part of the marginalization,
but should be included for purposes of finding the MLE. This defaults to
stochastic nodes that depend on \code{paramNodes} but are not part of and
do not depend on \code{randomEffectsNodes}. There may be deterministic
nodes between \code{paramNodes} and \code{calcNodesExtra}. These will
be included in calculations automatically and thus do not need to be
included in \code{calcNodesExtra} (but there is no problem if they
are).}

\item{control}{a named list (for \code{buildLaplace} only) that controls the
behavior of the Laplace approximation. See \code{control} section below.}
}
\description{
Builds a Laplace approximation algorithm for a given NIMBLE model.
}
\section{\code{buildLaplace}}{


This is the main function for constructing the Laplace approximation for a
given model. One only needs to provide a NIMBLE model object and then the
function will construct the pieces necessary for Laplace approximation to
marginalize over all latent states (aka random effects) in a model. To do so,
it will determine default values for \code{paramNodes},
\code{randomEffectsNodes}, \code{calcNodes}, and \code{calcNodesExtra} as
described above.

The default values are obtained by calling \code{setupMargNodes}, whose
arguments match those here (except for a few arguments which are taken from
control list elements here). One can call that function to see exactly how
nodes will be arranged for Laplace approximation. One can also call it,
customize the returned list, and then provide that to \code{buildLaplace} as
\code{paramNodes}.

If any \code{paramNodes} (parameters) or \code{randomEffectsNodes} (random
effects / latent states) have constraints on the range of valid values
(because of the distribution they follow), they will be used on a transformed
scale determined by \code{parameterTransform}. This means the Laplace
approximation itself will be done on the transformed scale for random effects
and finding the MLE will be done on the transformed scale for parameters. For
parameters, any prior distributions are not included in calculations, but
they are used to determine valid parameter ranges. For example, if
\code{sigma} is a standard deviation, declare it with a prior such as
\code{sigma ~ dhalfflat()} to indicate that it must be greater than 0.

The object returned by \code{buildLaplace} is a nimbleFunction object with
numerous methods (functions). The most useful ones are:

\itemize{

\item \code{Laplace(p)}. Laplace approximation to the marginal log-likelihood
      function at parameter value \code{p}, which should match the order of
      \code{paramNodes}. For any non-scalar nodes in \code{paramNodes}, the
      order within the node is column-major (which can be seen for R objects
      using \code{as.numeric}).

\item \code{findMLE(pStart, method, hessian)}. Find the maximum likelihood
        estimates of the Laplace-approximated marginal likelihood. Arguments
        include \code{pStart}: initial parameter values (defaults to
        parameter values currently in the model); \code{method}: (outer)
        optimization method to use in \code{optim} (defaults to "BFGS"); and
        \code{hessian}: whether to calculate and return the Hessian matrix
        (defaults to \code{TRUE}). Second derivatives in the Hessian are
        determined by finite differences of the gradients obtained by
        automatic differentiation (AD).

\item \code{summary(MLEoutput, originalScale,
       calcRandomEffectsStdError, returnJointCovariance)}. Summarize the
       maximum likelihood estimation results, given object
       \code{MLEoutput} that was returned by \code{findMLE}. The
       summary can include a covariance matrix for the parameters, the random
       effects, or both, and these can be returned on the original parameter
       scale or on the potentially transformed scale(s) used in estimation.

In addition, \code{summary} accepts the following optional arguments:

       \itemize{

          \item \code{originalScale}. Logical. If TRUE, the function returns
          results on the original scale(s) of parameters and random effects;
          otherwise, it returns results on the transformed scale(s). If there
          are no constraints, the two scales are identical. Defaults to TRUE.

          \item \code{calcRandomEffectsStdError}. Logical. If TRUE, standard
          errors of random effects will be calculated.
          Defaults to FALSE.

          \item \code{returnJointCovariance}. Logical. If TRUE, the joint
          variance-covariance matrix of the parameters and the random effects
          will be returned. Defaults to FALSE.

       }

       \code{summary} function returns a named list, with elements:

       \itemize{

          \item \code{params}. A list that contains estimates and standard
          errors of parameters (on the original or transformed scale, as
          chosen by \code{originalScale}).

          \item \code{random}. A list that contains estimates of random
          effects and, if requested (\code{calcRandomEffectsStdError=TRUE})
          their standard errors, on original or transformed scale. Standard
          errors are calculated following the generalized delta method of
          Kass and Steffey (1989).

          \item \code{vcov}. If requested (i.e.
          \code{returnJointCovariance=TRUE}), the joint variance-covariance
          matrix of the random effects and parameters, on original or
          transformed scale.

          \item \code{scale}. \code{original} or \code{transformed}, the
       scale on which results were requested.

       }

    }

Additional methods to access or control more details of the Laplace approximation include:

\itemize{

  \item \code{get_node_name_vec(returnParams)}. Return a vector (>1) of names
  of parameters/random effects nodes, according to \code{returnParams =
  TRUE/FALSE}. Use this is there is more than one parameter.

  \item \code{get_node_name_single(returnParams)}. Return the name of a
  single parameter/random effect node, \code{returnParams = TRUE/FALSE}. Use
  this if there is only one parameter.

  \item \code{set_method(method)}. Set method ID for calculating the Laplace
  approximation and gradient: 1 (\code{Laplace1}), 2 (\code{Laplace2},
  default method), or 3 (\code{Laplace3}). See below for more details. Users
  wanting to explore efficiency can try switching from method 2 (default) to
  methods 1 or 3 and comparing performance. The first Laplace approximation
  with each method will be (much) slower than subsequent Laplace
  approximations.

  \item \code{get_method()}. Return the current method ID.

  \item \code{one_time_fixes()}. Users do not need to run this. Is is called
  when necessary internally to fix dimensionality issues if there is only
  one parameter in the model.

  \item \code{extraLogLik(p)}. Calculate the \code{calcNodesExtra}
  nodes, which returns the log-likelihood of the parts of the model that are
  not included in the Laplace approximation. \code{p} is the vector of
  parameter values in the order of \code{paramNames}.

  \item \code{gr_extraLogLik_internal(p)}. Gradient (vector of
  derivatives with respect to each parameter) of \code{extraLogLik(p)}.
  This is obtained using automatic differentiation (AD) with single-taping.
  First call will always be slower than later calls.

  \item \code{gr_extraLogLik(p)}. Gradient (vector of derivatives with
  respect to each parameter) of \code{extraLogLik(p)}. This is obtained
  using automatic differentiation (AD) with double-taping. Results should
  match \code{gr_extraLogLik_internal(p)} but may be more efficient after
  the first call.

  \item \code{gr_Laplace(p)}. Gradient of the Laplace-approximated marginal
  likelihood at parameter value \code{p}.

  \item \code{p_transformed_Laplace(pTransform)}. Laplace approximation at
        transformed (unconstrained) parameter value \code{pTransform}. To
        make maximizing the Laplace likelihood unconstrained, an automated
        transformation via \code{\link{parameterTransform}} is performed on
        any parameters with constraints indicated by their priors (even
        though the prior probabilities are not used).

}

Finally, methods that are primarily for internal use by other methods include:

\itemize{

   \item \code{p_transformed_gr_Laplace(pTransform)}. Gradient of the Laplace
    approximation (\code{p_transformed_Laplace(pTransform)}) at transformed 
    (unconstrained) parameter value \code{pTransform}.

   \item \code{pInverseTransform(pTransform)}. Back-transform the transformed
   parameter value \code{pTransform} to original scale.

   \item \code{derivs_pInverseTransform(pTransform, order)}. Derivatives of
   the back-transformation (i.e. inverse of parameter transformation) with
   respect to transformed parameters at \code{pTransform}. Derivative order
   is given by \code{order} (any of 0, 1, and/or 2).

   \item \code{reInverseTransform(reTrans)}. Back-transform the transformed
   random effects value \code{reTrans} to original scale.

   \item \code{derivs_reInverseTransform(reTrans, order)}. Derivatives of the
   back-transformation (i.e. inverse of random effects transformation) with
   respect to transformed random effects at \code{reTrans}. Derivative order
   is given by \code{order} (any of 0, 1, and/or 2).

   \item \code{optimRandomEffects(pTransform)}. Calculate the optimized
   random effects given transformed parameter value \code{pTransform}. The
   optimized random effects are the mode of the conditional distribution of
   random effects given data at parameters \code{pTransform}, i.e. the
   calculation of \code{calcNodes}.

   \item \code{inverse_negHess(p, reTransform)}. Calculate the inverse of the
   negative Hessian matrix of the joint (parameters and random effects)
   log-likelihood with respect to transformed random effects, evaluated at
   parameter value \code{p} and transformed random effects
   \code{reTransform}.

   \item \code{hess_logLik_wrt_p_wrt_re(p, reTransform)}. Calculate the
   Hessian matrix of the joint log-likelihood with respect to parameters and
   transformed random effects, evaluated at parameter value \code{p} and
   transformed random effects \code{reTransform}.

}
}

\section{\code{control} list}{


\code{buildLaplace} accepts the following control list elements:

\itemize{

  \item \code{split}. If TRUE (default), \code{randomEffectsNodes} will be
        split into conditionally independent sets if possible. This
        facilitates more efficient Laplace approximation because each
        conditionally independent set can be marginalized independently. If
        FALSE, \code{randomEffectsNodes} will be handled as one multivariate
        block, with one multivariate Laplace approximation. If \code{split}
        is a numeric vector, \code{randomEffectsNodes} will be split by
        \code{split}(\code{randomEffectsNodes}, \code{control$split}). The
        last option allows arbitrary control over how
        \code{randomEffectsNodes} are blocked.

  \item \code{warn}. If TRUE (default), a warning is issued if
  \code{randomEffectsNodes} and/or \code{calcNodes} are provided but have
  extra or missing elements relative to their defaults.

  \item \code{innerOptimControl}. See \code{optimControl}.

  \item \code{innerOptimMethod}. See \code{optimMethod}.

  \item \code{innerOptimStart}. see \code{optimStart}.

  \item \code{outOptimControl}. A list of control parameters for maximizing
        the Laplace log-likelihood using \code{optim}. See 'Details' of
        \code{\link{optim}} for further information.

  \item \code{allowNonPriors} If FALSE (default), all parameter nodes must
  have stochastic declarations (i.e. priors). These are not calculated as
  part of Laplace approximation, but they are used to determine boundaries on
  the valid ranges of parameters. If TRUE, parameters do not need
  declarations, and those without one will be assumed to have no constraints
  on valid values.

}
}

\section{\code{AGHQuad_BASE}}{


Laplace base class, upon which specific Laplace algorithm classes are based
by including \code{contains = AGHQuad_BASE}. This declares a list of
nimbleFunctions for a single Laplace approximation. Intended for internal use
only.
}

\section{\code{buildOneAGHQuad1D}}{


This function constructs a single Laplace approximation when
\code{randomEffectsNodes} contains only one scalar node. It is mostly for
internal use by `buildLaplace`, when a scalar random effect is conditionally
independent from any other random effects. To use it directly, one has to
provide full inputs for all the arguments; there are no defaults.

This function generates an object that comprises a set of methods (functions), 
each accomplishing one piece of many calculations to obtain the Laplace 
approximation and its gradient w.r.t. model parameters. 

Among these methods, six are most useful to a user:

\itemize{

  \item \code{Laplace1(p)}. Laplace approximation evaluated at the parameter
  value \code{p}. This function uses single AD taping for gradient and
  Hessian calculations and separate components.

  \item \code{Laplace2(p)}. Laplace approximation evaluated at the parameter
  value \code{p}. This function uses double AD taping for gradient and
  Hessian calculations and separate components.

  \item \code{Laplace3(p)}. Laplace approximation evaluated at the parameter
  value \code{p}. This function uses double AD taping for gradient and
  Hessian calculations and packs everything together.

  \item \code{gr_Laplace1(p)}. Gradient of \code{Laplace1} with respect to
  parameters evaluated at the parameter value \code{p}.

  \item \code{gr_Laplace2(p)}. Gradient of \code{Laplace2} with respect to
  parameters evaluated at the parameter value \code{p}.

  \item \code{gr_Laplace3(p)}. Gradient of \code{Laplace3} with respect to
  parameters evaluated at the parameter value \code{p}.

}
}

\section{\code{buildOneAGHQuad}}{


This function constructs a single Laplace approximation when
\code{randomEffectsNodes} contains more than one dimension (i.e. has a
non-scalar node and/or multiple scalar nodes). It is mostly for internal use
by `buildLaplace`. To use it directly, one has to provide full inputs for all
the arguments; there are no defaults.

The methods generated by this function are the same as \code{buildOneAGHQuad1D}.
}

\examples{
pumpCode <- nimbleCode({ 
  for (i in 1:N){
    theta[i] ~ dgamma(alpha, beta)
    lambda[i] <- theta[i] * t[i]
    x[i] ~ dpois(lambda[i])
  }
  alpha ~ dexp(1.0)
  beta ~ dgamma(0.1, 1.0)
})
pumpConsts <- list(N = 10, t = c(94.3, 15.7, 62.9, 126, 5.24, 31.4, 1.05, 1.05, 2.1, 10.5))
pumpData <- list(x = c(5, 1, 5, 14, 3, 19, 1, 1, 4, 22))
pumpInits <- list(alpha = 0.1, beta = 0.1, theta = rep(0.1, pumpConsts$N))
pump <- nimbleModel(code = pumpCode, name = "pump", constants = pumpConsts, 
                    data = pumpData, inits = pumpInits, buildDerivs = TRUE)
                    
# Build Laplace approximation
pumpLaplace <- buildLaplace(pump)

\dontrun{
# Compile the model
Cpump <- compileNimble(pump)
CpumpLaplace <- compileNimble(pumpLaplace, project = pump)
# Calculate MLEs of parameters
MLEres <- CpumpLaplace$findMLE()
# Calculate estimates and standard errors for parameters and random effects on original scale
allres <- CpumpLaplace$summary(MLEres, calcRandomEffectsStdError = TRUE)
}

}
\references{
Kass, R. and Steffey, D. (1989). Approximate Bayesian inference in
conditionally independent hierarchical models (parametric empirical Bayes
models). \emph{Journal of the American Statistical Association}, 84(407),
717–726.

Skaug, H. and Fournier, D. (2006). Automatic approximation of the marginal
likelihood in non-Gaussian hierarchical models. \emph{Computational
Statistics & Data Analysis}, 56, 699–709.
}
\author{
Wei Zhang, Perry de Valpine
}
